{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Model_Bert_SE_WordEmbedding_Dialouge_SubjectiveAnnotations.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dff2a7f0922b4c60949bc1ee1d684acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f6ddd6834384b3a8934df32908ab99a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fa65d05e60d64216a7458ecb89aedb2f",
              "IPY_MODEL_2698676a9cd645bda2f4f92703f5b677"
            ]
          }
        },
        "0f6ddd6834384b3a8934df32908ab99a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fa65d05e60d64216a7458ecb89aedb2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ab7af14fa334279a805c009efd86913",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd3d66c15ad34672b2685ae0d4395246"
          }
        },
        "2698676a9cd645bda2f4f92703f5b677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_103e46694eae41e093f516e5c15fcaa3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.98kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42507dd877f048a8b2556e774638189e"
          }
        },
        "5ab7af14fa334279a805c009efd86913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd3d66c15ad34672b2685ae0d4395246": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "103e46694eae41e093f516e5c15fcaa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42507dd877f048a8b2556e774638189e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a43a16e393534ac1bacebe65570455b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f4c34a63280545148aa14e14fcf3e76b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_80ae826843e149a899dbf93733f08804",
              "IPY_MODEL_9f9923b7e1b9426894ab86d6b2c5d253"
            ]
          }
        },
        "f4c34a63280545148aa14e14fcf3e76b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80ae826843e149a899dbf93733f08804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9608241cd81248849f5963890f3765fe",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8723123959b44d1b5c4cae5ef918eca"
          }
        },
        "9f9923b7e1b9426894ab86d6b2c5d253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f52fe050bdcf4599976da0c2fe4c9870",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [05:10&lt;00:00, 1.42MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f84ec0674cd249589c26221fefad3658"
          }
        },
        "9608241cd81248849f5963890f3765fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8723123959b44d1b5c4cae5ef918eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f52fe050bdcf4599976da0c2fe4c9870": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f84ec0674cd249589c26221fefad3658": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitaiisc/EventFactuality/blob/master/Bert_Subjective_Annotations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUgNI4Ff3Xqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2beadcea-dc4a-4701-9cd6-8cb04963b58b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjjobWmv5GmV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f6bde66-c4c2-414f-a836-95dc7d836828"
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/Colab\\ Notebooks/EventFactuality/Neural_Modelling"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/EventFactuality/Neural_Modelling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozZtnCDy2yPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbX-sxe32yQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertModel\n",
        "import time\n",
        "import torch\n",
        "import argparse\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from typing import List, Mapping, Optional\n",
        "Outputs = Mapping[str, List[torch.Tensor]]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elGYXrAXJVeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy_with_probs(\n",
        "    input: torch.Tensor,\n",
        "    target: torch.Tensor,\n",
        "    weight: Optional[torch.Tensor] = None,\n",
        "    reduction: str = \"mean\",\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Calculate cross-entropy loss when targets are probabilities (floats), not ints.\n",
        "    PyTorch's F.cross_entropy() method requires integer labels; it does accept\n",
        "    probabilistic labels. We can, however, simulate such functionality with a for loop,\n",
        "    calculating the loss contributed by each class and accumulating the results.\n",
        "    Libraries such as keras do not require this workaround, as methods like\n",
        "    \"categorical_crossentropy\" accept float labels natively.\n",
        "    Note that the method signature is intentionally very similar to F.cross_entropy()\n",
        "    so that it can be used as a drop-in replacement when target labels are changed from\n",
        "    from a 1D tensor of ints to a 2D tensor of probabilities.\n",
        "    Parameters\n",
        "    ----------\n",
        "    input\n",
        "        A [num_points, num_classes] tensor of logits\n",
        "    target\n",
        "        A [num_points, num_classes] tensor of probabilistic target labels\n",
        "    weight\n",
        "        An optional [num_classes] array of weights to multiply the loss by per class\n",
        "    reduction\n",
        "        One of \"none\", \"mean\", \"sum\", indicating whether to return one loss per data\n",
        "        point, the mean loss, or the sum of losses\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        The calculated loss\n",
        "    Raises\n",
        "    ------\n",
        "    ValueError\n",
        "        If an invalid reduction keyword is submitted\n",
        "    \"\"\"\n",
        "    num_points, num_classes = input.shape\n",
        "    # Note that t.new_zeros, t.new_full put tensor on same device as t\n",
        "    cum_losses = input.new_zeros(num_points)\n",
        "    for y in range(num_classes):\n",
        "        target_temp = input.new_full((num_points,), y, dtype=torch.long)\n",
        "        y_loss = F.cross_entropy(input, target_temp, reduction=\"none\")\n",
        "        if weight is not None:\n",
        "            y_loss = y_loss * weight[y]\n",
        "        cum_losses += target[:, y].float() * y_loss\n",
        "\n",
        "    if reduction == \"none\":\n",
        "        return cum_losses\n",
        "    elif reduction == \"mean\":\n",
        "        return cum_losses.mean()\n",
        "    elif reduction == \"sum\":\n",
        "        return cum_losses.sum()\n",
        "    else:\n",
        "        raise ValueError(\"Keyword 'reduction' must be one of ['none', 'mean', 'sum']\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUs9_yK42yQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FactualityDataset(Dataset):\n",
        "\n",
        "    def __init__(self, filename, maxlen):\n",
        "\n",
        "        #Store the contents of the file in a pandas dataframe\n",
        "        self.df = pd.read_csv(filename, delimiter = '\\t')\n",
        "        #self.df = self.df[self.df.label!=3]\n",
        "        self.df.dropna(inplace=True)\n",
        "        self.df.reset_index(drop=True, inplace=True)\n",
        "        \n",
        "        #Initialize the BERT tokenizer\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        #Selecting the sentence and label at the specified index in the data frame\n",
        "        sentence = self.df.loc[index, 'sentence_dialouge']\n",
        "        label = self.df.loc[index, 'label']\n",
        "        source = self.df.loc[index, 'source']\n",
        "        event = self.df.loc[index, 'event']\n",
        "        source_idx = self.df.loc[index, 'source_index_dialouge']\n",
        "        event_idx = self.df.loc[index, 'event_index_dialouge']\n",
        "\n",
        "        prob_labels = list(self.df.loc[index, ['positive', 'negative', 'uncommitted', 'not_applicable']])\n",
        "\n",
        "        #Preprocessing the text to be suitable for BERT\n",
        "        tokens = self.tokenizer.tokenize(sentence) #Tokenize the sentence\n",
        "        \n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]'] #Insering the CLS and SEP token in the beginning and end of the sentence\n",
        "        if len(tokens) < self.maxlen:\n",
        "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
        "        else:\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
        "        \n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
        "\n",
        "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "        \n",
        "        source_idx = torch.tensor(source_idx)\n",
        "        event_idx = torch.tensor(event_idx)\n",
        "\n",
        "        return sentence, \"@\".join(tokens), source_idx, event_idx, tokens_ids_tensor, attn_mask, label, torch.tensor(prob_labels)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-qNSUqs2yQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, freeze_bert = True):\n",
        "        super(Classifier, self).__init__()\n",
        "        #Instantiating BERT model object \n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased', \\\n",
        "                                                    output_hidden_states = True)\n",
        "        \n",
        "        #Freeze bert layers\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_layer.parameters():\n",
        "                p.requires_grad = False\n",
        "        \n",
        "        #Classification layer\n",
        "        self.cls_layer_1 = nn.Linear(1536, 768)\n",
        "        self.cls_layer_2 = nn.Linear(768, 4)\n",
        "        \n",
        "    def get_word_embeddings(self, tokenized_text, tokenized_embedding):\n",
        "        '''\n",
        "        average the sub-token embeddings to get word embeddings\n",
        "        '''\n",
        "        word_embeddings = []\n",
        "        idx = 0\n",
        "        while(idx<len(tokenized_text)):\n",
        "            cur = tokenized_embedding[idx]\n",
        "            h_idx = idx+1\n",
        "            count = 1\n",
        "            while((h_idx<len(tokenized_text)) and ('#' in tokenized_text[h_idx])):\n",
        "                cur = cur + tokenized_embedding[h_idx]\n",
        "                count+=1\n",
        "                h_idx+=1\n",
        "            cur = cur/count\n",
        "            word_embeddings.append(cur)\n",
        "            idx = idx+count\n",
        "        word_embeddings = torch.stack(word_embeddings, dim=0)\n",
        "        return word_embeddings\n",
        "\n",
        "    def forward(self, seq, tokens, s_idx, e_idx, attn_masks):\n",
        "        '''\n",
        "        Inputs:\n",
        "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
        "            -attn_masks : Tensor of shape [B, T] containing attention masks \n",
        "                          to be used to avoid contibution of PAD tokens\n",
        "            -s_idx : tensor of shape [B] containing index of source in seq\n",
        "            -e_idx : tensor of shape [B] containing index of event in seq\n",
        "            -tokens: string containing textual tokens obtained from bert tokenizer.\n",
        "                     format of string t1@t2@t3....@tn\n",
        "        '''\n",
        "\n",
        "        #Feeding the input to BERT model to obtain contextualized representations\n",
        "        cont_reps, _, hidden_states = self.bert_layer(seq, attention_mask = attn_masks)\n",
        " \n",
        "        #Obtaining the representation of [CLS] head\n",
        "        #cls_rep = cont_reps[:, 0]\n",
        "\n",
        "        #Obtaining token embeddings from last layer\n",
        "        token_embeddings = torch.stack(hidden_states, dim=0)[-1]\n",
        "        \n",
        "        token_text = []\n",
        "        for t in tokens:\n",
        "            token_text.append(t.split('@'))\n",
        "            \n",
        "        word_embeddings = []\n",
        "        for te, emb in zip(token_text , token_embeddings):\n",
        "            word_embeddings.append(self.get_word_embeddings(te, emb))\n",
        "            \n",
        "        \n",
        "        se_embeddings = []\n",
        "        for b in range(len(word_embeddings)):\n",
        "            word_emb = word_embeddings[b]\n",
        "            source_emb = word_emb[s_idx[b]]\n",
        "            event_emb = word_emb[e_idx[b]]\n",
        "            emb = torch.cat((source_emb, event_emb))\n",
        "            se_embeddings.append(emb)\n",
        "        se_embeddings = torch.stack(se_embeddings, dim=0)\n",
        "        \n",
        "        if(se_embeddings.shape[1]!=1536):\n",
        "            print(torch.stack(hidden_states, dim=0).shape, token_embeddings.shape)\n",
        "        #print(se_embeddings.shape)\n",
        "        \n",
        "        h1 = self.cls_layer_1(se_embeddings)\n",
        "        logits = self.cls_layer_2(h1)\n",
        "        \n",
        "        #Feeding cls_rep to the classifier layer\n",
        "        #logits = self.cls_layer(cls_rep)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck1371772yQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy_from_logits(logits, labels):\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    _, preds = probs.max(1)\n",
        "    acc_val = torch.eq(preds, labels.squeeze()).float().mean()\n",
        "    return acc_val, preds\n",
        "\n",
        "def evaluate(net, criterion, dataloader, args):\n",
        "    net.eval()\n",
        "\n",
        "    mean_acc, mean_loss = 0, 0\n",
        "    count = 0\n",
        "    preds = []\n",
        "    true_labels = []\n",
        "    prob_labels = []\n",
        "    sentences = []\n",
        "    with torch.no_grad():\n",
        "        for sent, tokens, s_idx, e_idx, seq, attn_masks, labels, p_labels in dataloader:\n",
        "            seq, attn_masks, labels = seq.cuda(args.gpu), attn_masks.cuda(args.gpu), labels.cuda(args.gpu)\n",
        "            s_idx, e_idx = s_idx.cuda(args.gpu), e_idx.cuda(args.gpu)\n",
        "            \n",
        "            logits = net(seq, tokens, s_idx, e_idx, attn_masks)\n",
        "            \n",
        "            mean_loss += cross_entropy_with_probs(logits.squeeze(-1), p_labels).item()\n",
        "            acc, pred = get_accuracy_from_logits(logits, labels)\n",
        "            mean_acc += acc\n",
        "            preds.append(pred.detach().cpu().numpy())\n",
        "            true_labels.append(labels.detach().cpu().numpy())\n",
        "            prob_labels.append(p_labels.detach().cpu().numpy())\n",
        "            sentences.append(sent)\n",
        "            count += 1\n",
        "\n",
        "    return mean_acc / count, mean_loss / count, preds, true_labels, prob_labels, sentences"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKt3ZCX_2yQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, criterion, opti, train_loader, val_loader, args):\n",
        "\n",
        "    for ep in range(args.max_eps):\n",
        "        for it, (sent, tokens, s_idx, e_idx, seq, attn_masks, labels, p_labels) in enumerate(train_loader):\n",
        "            #Clear gradients\n",
        "            opti.zero_grad()  \n",
        "            \n",
        "            #Converting these to cuda tensors\n",
        "            seq, attn_masks, labels, p_labels = seq.cuda(args.gpu), attn_masks.cuda(args.gpu), labels.cuda(args.gpu), p_labels.cuda(args.gpu)\n",
        "            s_idx, e_idx = s_idx.cuda(args.gpu), e_idx.cuda(args.gpu)\n",
        "            \n",
        "            #Obtaining the logits from the model\n",
        "            #print('computing logits')\n",
        "            logits = net(seq, tokens, s_idx, e_idx, attn_masks)\n",
        "            #print('logits computed')\n",
        "            #Computing loss\n",
        "            loss = cross_entropy_with_probs(logits.squeeze(-1), p_labels)\n",
        "\n",
        "            #Backpropagating the gradients\n",
        "            loss.backward()\n",
        "\n",
        "            #Optimization step\n",
        "            opti.step()\n",
        "\n",
        "            if (it + 1) % args.print_every == 0:\n",
        "                acc, pred = get_accuracy_from_logits(logits, labels)\n",
        "                print(\"Iteration {} of epoch {} complete. Loss : {} Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PU-gg9w2yQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parser = argparse.ArgumentParser('')\n",
        "parser.add_argument('-gpu', type = int, default = 0)\n",
        "parser.add_argument('-freeze_bert', action='store_true')\n",
        "parser.add_argument('-maxlen', type = int, default= 128)\n",
        "parser.add_argument('-batch_size', type = int, default= 32)\n",
        "parser.add_argument('-lr', type = float, default = 2e-5)\n",
        "parser.add_argument('-print_every', type = int, default= 100)\n",
        "parser.add_argument('-max_eps', type = int, default= 5)\n",
        "args = parser.parse_args('')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbZA7ur92yQq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "dff2a7f0922b4c60949bc1ee1d684acd",
            "0f6ddd6834384b3a8934df32908ab99a",
            "fa65d05e60d64216a7458ecb89aedb2f",
            "2698676a9cd645bda2f4f92703f5b677",
            "5ab7af14fa334279a805c009efd86913",
            "bd3d66c15ad34672b2685ae0d4395246",
            "103e46694eae41e093f516e5c15fcaa3",
            "42507dd877f048a8b2556e774638189e",
            "a43a16e393534ac1bacebe65570455b8",
            "f4c34a63280545148aa14e14fcf3e76b",
            "80ae826843e149a899dbf93733f08804",
            "9f9923b7e1b9426894ab86d6b2c5d253",
            "9608241cd81248849f5963890f3765fe",
            "c8723123959b44d1b5c4cae5ef918eca",
            "f52fe050bdcf4599976da0c2fe4c9870",
            "f84ec0674cd249589c26221fefad3658"
          ]
        },
        "outputId": "6c99ee7d-ee2a-414f-d632-bbe3f80f2877"
      },
      "source": [
        "#Instantiating the classifier model\n",
        "print(\"Building model! (This might take time if you are running this for first time)\")\n",
        "st = time.time()\n",
        "net = Classifier(args.freeze_bert)\n",
        "net.cuda(args.gpu) #Enable gpu support for the model\n",
        "print(\"Done in {} seconds\".format(time.time() - st))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building model! (This might take time if you are running this for first time)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dff2a7f0922b4c60949bc1ee1d684acd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a43a16e393534ac1bacebe65570455b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Done in 23.48561143875122 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0UeGZfm2yQu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b47e2b9a-2d38-4c5f-bf37-69937675ec15"
      },
      "source": [
        "print(\"Creating criterion and optimizer objects\")\n",
        "st = time.time()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "opti = optim.Adam(net.parameters(), lr = args.lr)\n",
        "print(\"Done in {} seconds\".format(time.time() - st))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating criterion and optimizer objects\n",
            "Done in 0.0022614002227783203 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLX0dDcq2yQy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "17a4dbbd-2c24-4c92-9371-c6b4613c8380"
      },
      "source": [
        "#Creating dataloaders\n",
        "print(\"Creating train and val dataloaders\")\n",
        "st = time.time()\n",
        "train_set = FactualityDataset(filename = './FactualityData/processed_data/subjective_annotations/train_data_0.7_with_idx_dialouge.csv', maxlen = args.maxlen)\n",
        "val_set = FactualityDataset(filename = './FactualityData/processed_data/subjective_annotations/val_data_0.7_with_idx_dialouge.csv', maxlen = args.maxlen)\n",
        "train_loader = DataLoader(train_set, batch_size = args.batch_size, num_workers = 5)\n",
        "val_loader = DataLoader(val_set, batch_size = args.batch_size, num_workers = 5)\n",
        "print(\"Done in {} seconds\".format(time.time() - st))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating train and val dataloaders\n",
            "Done in 0.8139009475708008 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztpxwN-Q2yQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "df229d3b-5be7-4a68-9975-acfdf4bb4c95"
      },
      "source": [
        "print(\"Let the training begin\")\n",
        "st = time.time()\n",
        "train(net, criterion, opti, train_loader, val_loader, args)\n",
        "print(\"Done in {} seconds\".format(time.time() - st))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let the training begin\n",
            "Iteration 100 of epoch 1 complete. Loss : 0.21243607997894287 Accuracy : 0.9375\n",
            "Iteration 100 of epoch 2 complete. Loss : 0.2064167559146881 Accuracy : 0.96875\n",
            "Iteration 100 of epoch 3 complete. Loss : 0.15748175978660583 Accuracy : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC3XpZst2yQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_acc, mean_loss, preds, true_labels, prob_labels, sentences = evaluate(net, criterion, val_loader, args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhiGGuxJ2yRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = np.concatenate(preds)\n",
        "true_labels = np.concatenate(true_labels)\n",
        "prob_labels = np.concatenate(prob_labels)\n",
        "sentences = np.concatenate(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPAZ0Euv2yRI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg_ids = np.where(true_labels==1)[0]\n",
        "mis_clf = np.where(preds[neg_ids]!=1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaPMP_MW2yRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(sentences[neg_ids][mis_clf])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wcsf5To2yRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, precision_score, classification_report, recall_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAtZVWCF2yRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confusion_matrix(true_labels, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAMui6j62yRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Class Distribution in Orignal Dataset')\n",
        "print(' Class 0: , Percentage = 17% Pos ,\\n Class 1: , Percentage = 3% Neg,\\n Class 2: , Percentage = 7% Uncommited, \\n Class 3: , Percentage = 72% NA,')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcoymmNH2yRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(true_labels, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9gOwujA2yRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "precision_score(true_labels, preds, average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j64wE6R2yRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "recall_score(true_labels, preds, average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGxfcvse2yRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f1_score(true_labels, preds, average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eYVdm6O2yRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Class Distribution in Orignal Dataset')\n",
        "print(' Class 0: , Percentage = 17%,\\n Class 1: , Percentage = 3%,\\n Class 2: , Percentage = 7%, \\n Class 3: , Percentage = 72%,')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOwIlHRV2yRv",
        "colab_type": "text"
      },
      "source": [
        "#############################"
      ]
    }
  ]
}